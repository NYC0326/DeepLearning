import json
import pandas as pd

# arxiv JSON íŒŒì¼ ê²½ë¡œ (í˜„ìž¬ ë””ë ‰í† ë¦¬ ê¸°ì¤€)
JSON_PATH = "arxiv-metadata-oai-snapshot.json"
OUTPUT_PATH = "metadata/abstracts.csv"

# ìµœëŒ€ ë…¼ë¬¸ ìˆ˜ (í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ì œí•œ)
MAX_COUNT = 2000
TARGET_CATEGORY = "cs.CV"  # ì»´í“¨í„° ë¹„ì „ ì „ìš©
START_DATE = "2024-01-01"

# ë””ë ‰í† ë¦¬ ì¤€ë¹„
import os
os.makedirs("metadata", exist_ok=True)

print("ðŸ“¦ arXiv JSON ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")

# JSONì„ chunk ë‹¨ìœ„ë¡œ ì½ê³  í•„í„°ë§
data = []
with open(JSON_PATH, 'r', encoding='utf-8') as f:
    for line in f:
        paper = json.loads(line)

        if (
            paper.get("categories") and TARGET_CATEGORY in paper["categories"]
            and len(paper.get("abstract", "")) >= 100
            and paper.get("update_date", "0000") >= START_DATE
        ):
            data.append({
                "id": paper["id"],
                "title": paper["title"].strip().replace("\n", " "),
                "abstract": paper["abstract"].strip().replace("\n", " ")
            })

        if len(data) >= MAX_COUNT:
            break

print(f"âœ… {len(data)}ê°œ ë…¼ë¬¸ metadata ì¶”ì¶œ ì™„ë£Œ!")

# ì €ìž¥
pd.DataFrame(data).to_csv(OUTPUT_PATH, index=False)
print(f"ðŸ“„ ì €ìž¥ ì™„ë£Œ: {OUTPUT_PATH}")